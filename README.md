# ** üé≤  Pipeline de Dados ELT para Consumo da API Brasil.IO**

Este documento apresenta a especifica√ß√£o t√©cnica, arquitetura e funcionamento de um pipeline de **Extra√ß√£o, Carga e Transforma√ß√£o (ELT)** destinado ao processamento do dataset **gastos-diretos** disponibilizado pela API p√∫blica Brasil.IO.
O projeto contempla desde a ingest√£o de dados brutos at√© a gera√ß√£o de artefatos anal√≠ticos estruturados para consumo por ferramentas de Business Intelligence (BI) e modelos de Machine Learning (ML).

---

## **1. Requisitos e Prepara√ß√£o do Ambiente**

### **1.1. Cria√ß√£o do ambiente Python**

Criar e ativar um ambiente virtual utilizando `venv`:

```bash
python -m venv .venv
source .venv/bin/activate
```

### **1.2. Instala√ß√£o de depend√™ncias**

Instalar os pacotes necess√°rios via `pip` ou `uv`:

```bash
pip install -r requirements.txt
```

### **1.3. Vari√°veis de ambiente**

Criar um arquivo `.env` contendo:

```
API_TOKEN=SEU_TOKEN_BRASIL_IO
```

Essa vari√°vel √© utilizada para autentica√ß√£o nas requisi√ß√µes HTTP √† API.

### **1.4. Estrutura de diret√≥rios**

Criar a seguinte hierarquia de pastas:

```
dataset/
 ‚îú‚îÄ‚îÄ raw/
 ‚îú‚îÄ‚îÄ bronze/
 ‚îú‚îÄ‚îÄ silver/
 ‚îî‚îÄ‚îÄ gold/
```

---

## **2. Arquitetura Geral do Pipeline**

O pipeline segue o modelo de camadas do **Data Lakehouse**, organizado em Raw, Bronze, Silver e Gold.

### **2.1. Raw (Dados Brutos)**

* Cont√©m todos os dados obtidos diretamente da API Brasil.IO.
* Cada p√°gina da API √© salva individualmente em formato **JSON**.
* A coleta respeita:

  * limite aproximado de **1000 p√°ginas**;
  * tratamento autom√°tico de **rate limit 429**, com espera antes de retentar.

### **2.2. Bronze (Dados Padronizados em Parquet)**

* Consolida√ß√£o dos arquivos JSON da camada Raw.
* Convers√£o para **Parquet**, com compress√£o *snappy*.
* Particionamento estruturado em:

```
ano=YYYY / mes=MM
```

Essa etapa melhora interoperabilidade, performance e organiza√ß√£o dos dados.

### **2.3. Silver (Dados Tratados e Validados)**

A camada Silver representa a primeira etapa de transforma√ß√£o significativa.

Transforma√ß√µes aplicadas:

* **Tratamento de valores nulos** (especialmente em `valor`).
* **Padroniza√ß√£o textual** (mai√∫sculas, remo√ß√£o de espa√ßos excedentes).
* **Convers√£o de tipos num√©ricos** (`ano`, `mes`, `valor`).
* **Convers√£o de datas** quando aplic√°vel.
* **Aplica√ß√£o de regras de integridade e qualidade**:

  * colunas cr√≠ticas sem valores nulos (`ano`, `mes`, `nome_orgao`, `nome_favorecido`);
  * valida√ß√£o de intervalo de m√™s (1 a 12);
  * verifica√ß√£o de aus√™ncia de valores monet√°rios negativos.

Realiza-se tamb√©m uma **an√°lise explorat√≥ria b√°sica**, incluindo:

* contagem de registros;
* n√∫mero de √≥rg√£os distintos;
* faixa temporal dispon√≠vel;
* valor m√©dio dos pagamentos.

Os dados tratados s√£o registrados em formato **Parquet particionado**, mantendo o mesmo padr√£o da camada Bronze.

### **2.4. Gold (Dados Agregados e Modelados)**

A camada Gold representa a camada de **servi√ßo (Serving Layer)**, destinada ao consumo por analistas, aplica√ß√µes e modelos.

S√£o realizadas agrega√ß√µes orientadas a valor, por exemplo:

* total de gastos por √≥rg√£o, ano e m√™s.

Essa etapa caracteriza a gera√ß√£o de **data products**, estruturados para uso imediato, em formato Parquet e com o mesmo esquema de particionamento.

---

## **3. Funcionamento do Pipeline**

O arquivo `main.py` orquestra todas as etapas:

1. **fetch_and_save_raw_data()**
   Consulta a API Brasil.IO, trata pagina√ß√£o e limita√ß√µes, salva arquivos brutos.

2. **process_raw_to_bronze()**
   Converte e estrutura os dados brutos em Parquet particionado.

3. **process_bronze_to_silver()**
   Aplica regras de limpeza, padroniza√ß√£o e valida√ß√£o de qualidade.

4. **process_silver_to_gold()**
   Gera tabelas agregadas de alto valor anal√≠tico.

Para executar:

```bash
python main.py
```

---

## **4. Considera√ß√µes sobre o Ciclo de Vida dos Dados**

### **Transform (T)**

Corresponde √† etapa em que os dados deixam sua forma original para assumirem um formato estruturado, limpo e √∫til para casos de uso *downstream*.
Transforma√ß√µes em lote (batch) ‚Äî como neste projeto ‚Äî s√£o amplamente utilizadas em pipelines tradicionais e modernos.

### **Camada Gold e Uso Final**

A camada Gold representa a fase final do ciclo, com dados prontos para:

* an√°lises descritivas e diagn√≥sticas,
* modelagem preditiva,
* ingest√£o por ferramentas de BI,
* execu√ß√£o de processos de Reverse ETL.

Essa camada cont√©m dados j√° agregados, coerentes e validados, otimizados para consultas r√°pidas e decis√µes de neg√≥cio.

---

## **5. Resultado Final**

Ao final da execu√ß√£o completa, obt√©m-se:

* **Raw**: dados brutos da API Brasil.IO;
* **Bronze**: Parquets estruturados e pr√≥ximos do estado original;
* **Silver**: dados limpos, padronizados e aprovados em testes de qualidade;
* **Gold**: artefatos anal√≠ticos prontos para uso corporativo.

O projeto entrega um pipeline ELT robusto, modular, escal√°vel e alinhado √†s melhores pr√°ticas contempor√¢neas de Engenharia de Dados.

---

Se desejar, posso gerar a vers√£o em **PDF**, produzir um **diagrama da arquitetura** ou criar **exemplos de dashboards** consumindo a camada Gold.
